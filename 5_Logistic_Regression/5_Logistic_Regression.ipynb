{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Logistic Regression is a method when the variable to be determined(the dependent variable) is categorical. It might be helpful to think of it as a probabilistic classification model. It is used to assign observations to a discrete set of classes. Logistic regression transforms its output using the logistic sigmoid function to return a probability value which can then be mapped to two or more discrete classes. For example, To predict\n",
    "\n",
    "1. If an email is spam(1) or not(0)\n",
    "2. If a given image is of a cat(1) or not(0)\n",
    "3. If a tumor is malignant(1) or not(0)\n",
    "\n",
    "> Although multiclass classification is possible as well (ex: Movie Rating from 1 to 5, or food preference between vegan, veg or non-veg) it is beyond the scope of this course. Feel free to read up about it and ask us about any doubts regarding the same\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Comparison To Linear Regression\n",
    "\n",
    "Where Linear Regression is used to predict continuous numerical values, Logistic Regression's predictions are discrete (only certain values or categories are allowed). It represents the probability of the sample belonging to a particular category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Binary Logistic Regression\n",
    "Say you are given data on student exam results, and your goal is to predict whether a student will pass or fail based on the number of hours slept, and the hours studied. In this case we have,\n",
    "1. Features: \n",
    " - Hours Slept\n",
    " - Hours Studied\n",
    "2. Classes:\n",
    " - Pass(1)\n",
    " - Fail(0)\n",
    " \n",
    "Ex:\n",
    "\n",
    "Studied (hrs) | Slept (hrs) | Result |\n",
    "--------------| ----------- | -------|\n",
    "4.85 | 9.63 | 1\n",
    "8.62 | 3.23 | 0\n",
    "5.43 | 8.23 | 1\n",
    "st | sl | ?\n",
    "\n",
    " \n",
    "So in this case we need to calculate that given a student has slept for $ sl $ hours and studied for $ st $ for a test what is the probability that he will pass, and what is the probability that he will fail. More Formally,\n",
    "\n",
    "$$ P(result = Pass | Slept = sl, Studied = st) $$ and\n",
    "$$ P(result = Fail | Slept = sl, Studied = st) $$\n",
    "\n",
    "Or, abstracting into variables, \n",
    "\n",
    "$$ p = P(Y = 1 | x_1, x_2, ..., x_n) $$ \n",
    "$$ q = P(Y = 0 | x_1, x_2, ..., x_n) $$\n",
    "\n",
    "where, \n",
    "> Y is the class that the sample data belongs to\n",
    "> $x_i$ are the various features of the data\n",
    "\n",
    "Now, notice that since $p$ and $q$ are the only possible classes and represent probabilities,\n",
    "\n",
    "$$ p + q = 1 $$ \n",
    "\n",
    "and calculating any one of them is sufficient to find the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 The Linear Function\n",
    "\n",
    "The first Step in creating a Logistic regression Model is similar to a linear regression Model. We need to take a linear combination of all the features, and a constant amount to it. In Linear Regression you saw them called as parameters, labeled as $\\theta$:\n",
    "\n",
    "$$ h_\\theta(x) = \\theta_0 + \\theta_1x_1 + \\theta_2x_2 + ... + \\theta_nx_n $$\n",
    "or, in vectorized form:\n",
    "$$ h_\\theta(x) = x \\cdot \\theta $$\n",
    "\n",
    "From here on we will be using the notation more commonly used in Neural Network Architectures. \n",
    "The $\\theta_0$ term is called the bias, and the parameters $\\theta_1, \\theta_2, ..., \\theta_n $ the weights.\n",
    "\n",
    "The Output of the linear Function is now represented as: \n",
    "\n",
    "$$ z(x) = w_1x_1 + w_2x_2 + ... + w_nx_n + b $$\n",
    "> where:\n",
    "1. $z$ is a scalar,\n",
    "2. $w_i$ are the scalar weights\n",
    "3. $b$ is the sclar bias\n",
    "\n",
    "Now, this can also be written as a matrix product as follows:\n",
    "\n",
    "$$ z = w \\cdot x + b $$\n",
    "\n",
    "> where,\n",
    "1. $x$ = feature vector of shape $(n_x, 1) = (x_1, x_2, ..., x_n)$ stacked in a column\n",
    "2. $w$ = weight matrix of shape $ (1, n_x) = [[w_1], [w_2], ..., [w_3]]$ stacked in a row\n",
    "3. $b$ = scalar bias\n",
    "\n",
    "And as always, a linear function is unbounded and so, \n",
    "$$ z \\in (-\\infty, \\infty) $$\n",
    "\n",
    "> If at any point you are confused with notation, check the Notation Section at the bottom. There is a quick reference there, and if the doubt still persists PM one of us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Activation Functions: The Sigmoid Function\n",
    "As you already saw in Linear Regression, the function $z = w \\cdot x + b$ is unbounded. However, since we are calculating the probability, we need to scale the value of $Z$ (obtained from Linear Regression) to the range $[0, 1]$. To achieve this we use the Sigmoid function.\n",
    "\n",
    "The sigmoid, or the logistic Function is a special function which maps its input to values between 0 and 1. It is an S shaped curve defined by the following equation:\n",
    " \n",
    "$$ S(z) = \\sigma(z) = \\frac{1}{1 + e^{-z}} $$\n",
    " \n",
    "> Notes:\n",
    "> 1. $S(Z) \\in [0, 1] $\n",
    "> 2. z = Input to your function (The prediction of the linear regression model, ie: $wx + b$\n",
    "\n",
    "<img src=\"https://ml-cheatsheet.readthedocs.io/en/latest/_images/sigmoid.png\">\n",
    "\n",
    "> Try to find other functions with similar properties, or similar shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWrite the code for logistic Regression\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Write the code for logistic Regression in numpy\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Decision Boundary\n",
    "Our current Prediction returns a probability between 0 and 1. In order to map this value to a discrete class, we select a threshold value or the tipping point. All values aobe this tipping point are classified into \"Class 1\", and all below to \"Class 2\".\n",
    "\n",
    "For example if our threshold value was 0.5,\n",
    "\n",
    "$$ p \\ge 0.5 \\implies class = 1 $$\n",
    "$$ p \\lt 0.5 \\implies class = 2 $$\n",
    "\n",
    "<img src=\"https://ml-cheatsheet.readthedocs.io/en/latest/_images/logistic_regression_sigmoid_w_threshold.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Making Predictions\n",
    "\n",
    "Using our knowledge of sigmoid functions and decision boundaries, we can now write a prediction function. A prediction function in logistic regression returns the probability of our observation being positive, True, or “Yes”. We call this class 1 and its notation is $P(class=1)$.\n",
    "\n",
    "As the probability gets closer to 1, our model is more confident that the observation is in class 1.\n",
    "\n",
    "Given: the feature vector, weight matrix and bias\n",
    "1. Linear function: \n",
    "    $$ z = w\\cdot x + b $$\n",
    "2. Applying activation: \n",
    "    $$ P(class = 1) = a = \\hat y = S(z) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWrite code for predictions\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Write code for predictions\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 The Loss Function: Log Loss\n",
    "\n",
    "For a linear regression model you used the MSE Loss. However, the same can not be applied here. Why? There is a great math explanation in chapter 3 of Michael Neilson’s deep learning [book](http://neuralnetworksanddeeplearning.com/chap3.html), but for now I’ll simply say it’s because our prediction function is non-linear (due to sigmoid transform). Squaring this prediction as we do in MSE results in a non-convex function with many local minimums. If our cost function has many local minimums, gradient descent may not find the optimal global minimum.\n",
    "\n",
    "Instead of the MSE we will use a loss function called the Cross-Entropy Loss or the Log Loss (denoted by $\\mathcal{L}(\\hat y, y)$. Cross Entropy loss can be divided into two separate loss functions: one for y = 1, and other for y = 0.\n",
    "\n",
    "1. if $y = 1$:\n",
    "$$ \\mathcal{L}(\\hat y, 1) = -\\log(\\hat y) $$ \n",
    "2. if $y = 0$:\n",
    "$$ \\mathcal{L}(\\hat y, 0) = -\\log(1 - \\hat y) $$ \n",
    "\n",
    "The benefits of taking the logarithm reveal themselves when you look at the loss function graphs for $y=1$ and $y=0$. These smooth monotonic functions (always increasing or always decreasing) make it easy to calculate the gradient and minimize cost. \n",
    "\n",
    "-|-\n",
    "- | - \n",
    "![alt](https://ik.imagekit.io/xtne6rmcgk/log_y__TYrTvZTL-.png) | ![alt](https://ik.imagekit.io/xtne6rmcgk/log2_uvK-wwZ7Y.png)\n",
    "\n",
    "These expressions can be combined to give:\n",
    "\n",
    "$$ \\mathcal{L} (\\hat y, y) = -[y\\log(\\hat y) + (1 - y)\\log(1 - \\hat y)] $$\n",
    "\n",
    "> Exercise: Prove the above is true\n",
    "\n",
    "> Loss function and Cost function are almost synonymous, with a small caveat that we will get to later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Gradient Descent\n",
    "\n",
    "To minimize our cost, we use Gradient Descent just like before in Linear Regression. \n",
    "\n",
    "> There are other more sophisticated optimization algorithms out there such as Momentum, or RMSProp or ADAM, but you don’t have to worry about these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Introduction\n",
    "\n",
    "In this era of deep learning, where machines have already surpassed human intelligence it’s fascinating to see how these machines are learning just by looking at examples. When we say that we are training the model, it’s gradient descent behind the scenes who trains it.\n",
    "\n",
    "So let’s dive deeper to have a look at gradient descent.\n",
    "\n",
    "This is what Wikipedia has to say on Gradient descent\n",
    "> Gradient descent is a first-order iterative optimization algorithm for finding the minimum of a function\n",
    "\n",
    "This seems little complicated, so let’s break it down.\n",
    "The goal of the gradient descent is to minimise a given function which, in our case, is the loss function of the Logistic Regresion Classifier. To achieve this goal, it performs two steps iteratively.\n",
    "\n",
    "1. Compute the slope (gradient) that is the first-order derivative of the function at the current point\n",
    "2. Move-in the opposite direction of the slope increase (from the current point) by the computed amount\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*P7z2BKhd0R-9uyn9ThDasA.png\">\n",
    "\n",
    "Think of it like this. Suppose you are at top of mountain, and want to get to the bottom of the valley. So you go down the slope. You decide your next position based on your current position and stop when you get to the bottom of the valley which was your goal.\n",
    "\n",
    "Now, consider the 3-dimensional graph below in the context of a cost function. Our goal is to move from the mountain in the top right corner (high cost) to the dark blue sea in the bottom left (low cost). The arrows represent the direction of steepest descent (negative gradient) from any given point–the direction that decreases the cost function as quickly as possible.\n",
    "\n",
    "<img src=\"https://ml-cheatsheet.readthedocs.io/en/latest/_images/gradient_descent.png\">\n",
    "\n",
    "Starting at the top of the mountain, we take our first step downhill in the direction specified by the negative gradient. Next we recalculate the negative gradient (passing in the coordinates of our new point) and take another step in the direction it specifies. We continue this process iteratively until we get to the bottom of our graph, or to a point where we can no longer move downhill–a local minimum.\n",
    "\n",
    "Now the loss of your model depends upon the parameters: weights and biases that we use in computation. S throught gradient descent, we update the parameters of our model. Let's look at that in the next secction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Mathematics\n",
    "\n",
    "The Loss Functions tells us “how good” our model is at making predictions for a given set of parameters. The cost function has its own curve and its own gradients. The slope of this curve tells us how to update our parameters to make the model more accurate.\n",
    "\n",
    "There are two parameters in our cost function we can control: $w$ (weight) and $b$ (bias). Since we need to consider the impact each one has on the final prediction, we need to use partial derivatives. We calculate the partial derivatives of the cost function with respect to each parameter and store the results in a gradient.\n",
    "\n",
    "We have the following equations:\n",
    "\n",
    "1. $ z = w \\cdot x + b $\n",
    "2. $ \\hat y = S(z) $\n",
    "3. $ \\mathcal{L} (\\hat y, y) = -[y\\log(\\hat y) + (1 - y)\\log(1 - \\hat y)] $\n",
    "\n",
    "and what we need to compute \n",
    "$$ \\frac{\\partial \\mathcal{L}}{\\partial w}, \\frac{\\partial \\mathcal{L}}{\\partial b} $$\n",
    "\n",
    "And for this we will use the chain rule as follows:\n",
    "\n",
    "$$ \\implies \\frac{\\partial \\mathcal{L}}{\\partial w} = \\frac{d\\mathcal{L}}{d\\hat y} \\cdot \\frac{d \\hat y}{dz} \\cdot \\frac{\\partial z}{\\partial w} $$\n",
    "\n",
    "and\n",
    "\n",
    "$$ \\implies \\frac{\\partial \\mathcal{L}}{\\partial w} = \\frac{d\\mathcal{L}}{d\\hat y} \\cdot \\frac{d \\hat y}{dz} \\cdot \\frac{\\partial z}{\\partial w} $$\n",
    "\n",
    "> Solve these on your own and get to the requires solution. It might be tricky, but the concept from  MATH F111 and MATH F112 should help\n",
    "\n",
    "> Hint 1: The derivative o the sigmoid function is given by:\n",
    "$$ \\frac{dS(z)}{dz} = S(z)(1 - S(z)) $$\n",
    "Hint 2: \n",
    "For reasons you will soon see, the shape of $ \\frac{\\partial \\mathcal{L}}{\\partial w}$ and $ w $ must be equal. Similarly for $b$\n",
    "\n",
    "The Final solution for these equations has the following structure:\n",
    "\n",
    "$$ \\implies \\frac{\\partial \\mathcal{L}}{\\partial w} = (\\hat y - y) \\cdot x^T $$\n",
    "\n",
    "$$ \\implies \\frac{\\partial \\mathcal{L}}{\\partial b} = (\\hat y - y) $$\n",
    "\n",
    "Now, we must update our parameters $ w $ and $ b $ by \"Taking a step down\" the slope. We do this by subtracting the derivatives with the respective Paramters:\n",
    "\n",
    "$$ w := w - \\frac{\\partial \\mathcal{L}}{\\partial w} $$\n",
    "$$ b := b - \\frac{\\partial \\mathcal{L}}{\\partial b} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Learning Rate\n",
    "\n",
    "Coming back to the mountain trekking analogy. Now imagine, instead of you there is a giant with huge fucken feet, and an ant trying to reach the same ending point, the valley (minima) from the same starting point, top of the mountain (maxima). Now, notice that the giant can never reach the valley and will always keep moving somewhere around him, no matter how small of a step he takes owing to the sheer size of his feet. And on the other hand, the ant being that small will take a very long time to reach the valley, but will reach never the less. So the problem in this case is the scale of the steps that the person can take.\n",
    "\n",
    "Similary, depending upon the context, the slope or the gradient might be too large or too small to reach the minima. So, to deal with the problem we scale the slope with a constant amount, before updating the parameters of the model. This scale factor is called the learning rate, denoted by $\\alpha$.\n",
    "\n",
    "So, the resulting expression is\n",
    "\n",
    "$$ \\theta := \\theta - \\alpha \\frac {\\partial \\mathcal {L}}{\\partial \\theta} $$ where $\\theta$ denotes the parameters of the model, $w$ and $b$.\n",
    "\n",
    "> Note: It is almost always that the slope is too large to reach the gradient, and you will almost never encounter a learning rate greater than 1\n",
    "\n",
    "Abstracting the analogy to provide intuition:\n",
    "\n",
    "1. With a high learning rate we can cover more ground each step, but we risk overshooting the lowest point since the slope of the hill is constantly changing. \n",
    "2. With a low learning rate, we can confidently move in the direction of the negative gradient since we are recalculating it so frequently. \n",
    "3. A very low learning rate is more precise, but calculating the gradient is time-consuming, so it will take us a very long time to get to the bottom.\n",
    "\n",
    "> A low learning rate might also get stuck in a local minima, as it is also a point of 0 gradient.\n",
    "This is why we used a log loss. It has only a gloabal minimum, and not local Minima where we can get stuck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the final algorithm for the gradient descent Optimizelooks like: \n",
    "\n",
    "$$ w := w - \\alpha \\frac{\\partial \\mathcal{L}}{\\partial w} $$\n",
    "\n",
    "\n",
    "$$ b := b - \\alpha \\frac{\\partial \\mathcal{L}}{\\partial b} $$\n",
    "\n",
    "This process must be repeat thousands of time, before we can reach the minima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training your Model\n",
    "\n",
    "Now that you are reasonably familiar with gradient descent, you will see how we will optimize our model. \n",
    "\n",
    "Lets first look at the the word dataset, in the context of machine learning. \n",
    "\n",
    "Consider you want to classify a given set of draings as \"Image of cat\", or \"Not Image of cat\". This is one of the many usecases of Logistic Regression. Consider that each drawing is done in a canvas of size 28x28 pixels, and is a graysale image.\n",
    "\n",
    "**TODO: Add image**\n",
    "\n",
    "Now a logistic regression algorithm, can not handle 2D data, so you flatten the image and use that as your feature vector. So, in this case, $n_x = 28 \\cdot 28 = 784 $ and each sample of your dataset has the shape $(784, 1)$. Also, you typically have thousands, or even hundred thousands of data samples, to optimize your model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Optimizing your model\n",
    "\n",
    "Optimizing the Model is achieved via reducing the loss to minimum via an optimization algorithm. The optimization algorithm we will be using is gradient descent. \n",
    "\n",
    "So, now you need to make a Logistic Regression model. This model will have a weights matrix, $w$ of shape $(1, 784)$ and a bias, $b$. In the beginning, these parameters will have small random values and over the several iterations of gradient descent, these parameters will be optimized for classification. \n",
    "\n",
    "The final algorithm for the Gradient Descent in pseudo code looks like this:\n",
    "\n",
    "```python\n",
    "X_train, Y_train = get_training_dataset() # X has shape (n_x, m) and Y as shape (1, m)\n",
    "w, b = initialize_parameters()\n",
    "alpha = 0.5 # Or any small value, can be tuned for better performance\n",
    "\n",
    "for i in (0, X.shape[1]):\n",
    "    x = X_train[:, i]\n",
    "    y = Y_train[:, i]\n",
    "    a = forward_propagate(w, b)\n",
    "    dw, db = backward_propagate(a, y, x)\n",
    "\n",
    "    w = w - alpha * dw\n",
    "    b = b = alpha * db\n",
    "\n",
    "```\n",
    "> Try to get accustomed to the code, and try figuring out what the forward_propagate and backward_propagate functions should look like. \n",
    "\n",
    "### This method, of iterating over 1 example at a time is called stochastic gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Splitting the dataset - Train and Test sets\n",
    "\n",
    "Now, notice that while procuring the data, I called them $X_{train}$, and $Y_{train}$. This is beacuse this data comprises what is called the \"Training dataset\" or the \"Train set\".\n",
    "\n",
    "In machine learning, any dataset you have is broadly split into two different parts, training data and testing data. Training data is used to optimize your model and enable it to reach the global minima.  The testing data is used to determine the accuracy of your model. The testing data, is the subset of your dataset, which your model, has never \"seen\" before. That is, the Logistic regression model was never trained on the testinfg data.\n",
    "\n",
    "The training and testing data are not evenly split. Your main dataset is typically split in the 8:2 ratio, or 9:1 ratio. For example, if you have 10,000 data points, your training set has size 8000, and test set has size 2000. \n",
    "\n",
    "The number of examples you have in your train set, or the number of samples in your train set is denoted by $m$.\n",
    "\n",
    "And, the number of samples in your entire dataset be denoted by $M$.\n",
    "#### VERY IMPORTANT NOTE: NEVER TRAIN YOUR MODEL ON YOUR TEST SET \n",
    "\n",
    "> For higher dimensional and more complicated models, the data is split in 3 parts into train, dev, and test set. The purpose of the dev set is beyong the scope of this course.\n",
    "> In case you have a much bigger dataset, say of the size 5 million data points, the split is much more skewed, for exmaple 99:1, or 99 : 0.5 : 0.5.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, what we have done till now is using forward propagation calculated the Linear Function, $z$ and the output $\\hat y$, or $a$, for one data sample at a time. Then calculated the derivatives using backpropagation, and updated the parameters. \n",
    "\n",
    "\n",
    "Now, while using the algorithm you will find that the training process is quite slow. This is because iterating to each training example one by one, is very time consuming. To replace this, we will use a new algorithm to train our data. This approach is a vectorized implementation of the Stochastic Gradient Descent Process, and takes advantage of the fast matrix multiplication implementations of numpy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Batch Gradient Descent\n",
    "\n",
    "Till now the shapes of the different elemets of our gradient decent algorithm have been:\n",
    "1. $x$.shape = $(n_x, 1)$\n",
    "2. $w$.shape = $(1, n_x)$\n",
    "3. $b$ is a 1D scalar\n",
    "4. $y$ is a 1D scalar\n",
    "5. $\\hat y$ or $a$ is a 1D scalar\n",
    "\n",
    "\n",
    "What we will do in this case, is instead of iterating over one data sample at a time, we process the entire training dataset at once. \n",
    "\n",
    "Let's denote the entire input data (ie all the different samples of input data $x$, of shape $(n_x, 1)$, stacked in columns against one another) by $X$. So, $X$ has shape $(n_x, M)$. And Splitting the data into train and test batches gives the following results, \n",
    "\n",
    "1. $X_{train}$ has shape = $(n_x, m)$\n",
    "2. $X_{test}$ has shape = $(n_x, M - m)$\n",
    "\n",
    "And similarly stacking all the $y$s, gives $Y$ of shape $(1, M)$. And splitting those,\n",
    "\n",
    "1. $Y_{train}$ has shape = $(1, m)$\n",
    "2. $Y_{test}$ has shape = $(1, M - m)$\n",
    "\n",
    "Each inidividual example is denoted by a **superscipted parantheses** \n",
    "ex: $X_{train}^{(i)}$ represents the $i^{th}$ training sample, and $ i\\in (0, m]$ \n",
    "\n",
    "1. $X^{(i)}$ has the shape $(n_x, 1)$\n",
    "2. $Y^{(i)}$ has the shape $(1, 1)$ and is basically a scalar\n",
    "\n",
    "This vectorization also changes the mathematics slightly. The cost function and the gradient changes slightly. Lets Look at that next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Cost Function for Batch Gradient Descent\n",
    "\n",
    "Till now we were dealing with single examples and the loss automatically turned out to be a scalar value. The cost of the model, although used synonymously to loss till now, is a contextually different variable. \n",
    "\n",
    "The difference between them is subtle. Loss is the special \"distance\" function calculated between a single output sample, and its predicted value. Cost on the other hand, is the mean of the loss over your entire training set. For stochastic gradient descent, since the training sample consisted of the single data point, it's mean was itself, and hence the loss was the cost. However, now when we are optimizing the model based on the m samples from the dataset at once, we will take the mean of the loss over all the samples.\n",
    "\n",
    "Hence, \n",
    "The loss is given by: \n",
    "\n",
    "$$ \\mathcal{L} (A^{(i)}, Y^{(i)}) = -[Y^{(i)}\\log(A^{(i)}) + (1 - Y^{(i)})\\log(1 - A^{(i)})] $$\n",
    "\n",
    "and the cost is given by:\n",
    "\n",
    "$$ J = \\frac{-1}{m} \\sum_1^m {\\mathcal{L} (A^{(i)}, Y^{(i)})} $$\n",
    "\n",
    "$$ \\implies J = \\frac{-1}{m} \\sum_1^m {Y^{(i)}\\log(A^{(i)}) + (1 - Y^{(i)})\\log(1 - A^{(i)})} $$\n",
    "\n",
    "> While training, it is the cost that we aim to reduce to minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Gradient Calculation\n",
    "\n",
    "From the previous calculations, Forward Propagation has the following equations:\n",
    "\n",
    "$$Z = w \\cdot X + b$$\n",
    "$$\\hat Y = A = S(Z)$$\n",
    "$$ J = \\frac{-1}{m} \\sum_1^m {Y^{(i)}\\log(A^{(i)}) + (1 - Y^{(i)})\\log(1 - A^{(i)})} $$\n",
    "\n",
    "> Note: You might notice that although, $w \\cdot X$ is a $(1, m)$ row vector, b is a scalar. So how does the addition operation take place? In reality b must also be a row vector of the same shape, ie $(1, m)$. To achieve this you can multiply b to a row vector of ones with the shape $(1, m)$. However, in numpy such operation are already predefined and you need not worry about it. The scalar is \"broadcasted\" into the required shape and the operation perfromed automatically.\n",
    "\n",
    "And the derivativves wee need to compute are $\\frac{\\partial J}{\\partial w}$ and $\\frac{\\partial J}{\\partial b}$.\n",
    "\n",
    "The calculation of these derivatives although, not as straight forward as earlier is a good exercise and left to the reader. \n",
    "\n",
    "> Hint: \n",
    "\n",
    "These derivatives, are calculated as follows:\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial w} = \\frac{1}{m} (A - Y) \\cdot X^T $$\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_1^m (A - Y) $$\n",
    "\n",
    "Which, are incredibly similar to the results seen earlier. \n",
    "\n",
    "And, finally the Batch gradient descent algorithm results in the following,\n",
    "\n",
    "$$ w := w - \\alpha \\frac{\\partial J}{\\partial w} $$\n",
    "\n",
    "$$ b := b - \\alpha \\frac{\\partial J}{\\partial b} $$\n",
    "\n",
    "With this, we come to the end of the gradient Descent Algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing your model and Predicting Values\n",
    "\n",
    "Predicitions from your Logistic Regression Model are very easy to compute, and all you need to do is compute the probability and check if it is above the predefined threshold value, usually 0.5. \n",
    "\n",
    "Quantiatively, \n",
    "\n",
    "$$\\hat Y = S(w \\cdot X + b)$$\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    Y_{prediction}^{(i)} =\n",
    "    \\begin{cases} \n",
    "        1 \\text{, if } \\hat Y^{(i)} \\ge 0.5\\\\\n",
    "        0 \\text{, if } \\hat Y^{(i)} \\lt 0.5\\\\\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    " \n",
    " \n",
    "For testing your model, compute the $ Y_{prediction, testing}^{(i)}$ on your testing data. From this, element wise comparison can be drawn and accuracy of your model evaluated. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
